{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['004354', '096824', '010011', '001852', '018457', '013840', '090299', '010560', '021131', '034102', '027653', '090870', '009243', '030342', '033612', '012009', '011228', '010145', '014839', '098510', '038920', '007099', '035090', '013842', '034078', '097764', '005235', '029574', '093705', '093072', '022507', '026981', '090676', '028303', '097380', '018331', '005860', '039157', '020851', '013527', '023325', '012773', '013530', '019435', '029849', '038083', '094118', '013860', '028294', '016535', '024799', '024709', '012946', '098173', '095219', '030187', '007216', '003571', '017452', '033630', '025236', '008595', '004207', '007050', '009157', '021955', '017629', '021295', '028779', '097539', '000033', '011696', '031073', '007562', '004146', '010497', '001324', '096187', '094160', '030867', '005494', '029987', '012552', '091066', '093137', '020792', '092875', '003924', '007069', '099025', '034257', '029389', '091937', '019564', '098293', '021292', '098199', '022273', '032988', '033624']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "path = \"/media/NLP/simple_manipulation\"\n",
    "train_path = os.path.join(path, \"train\")\n",
    "val_path = os.path.join(path, \"val\")\n",
    "test_path = os.path.join(path, \"test\")\n",
    "\n",
    "train = os.listdir(train_path)\n",
    "train = train[0:100]\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu.ipynb  test.ipynb  test-load_data.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls $element_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pose0_position': array([[0.4625    , 0.109375  , 0.05065918]], dtype=float32),\n",
       " 'pose0_rotation': array([[0., 0., 0., 1.]], dtype=float32),\n",
       " 'pose1_position': array([[0.58200645, 0.38126525, 0.03315918]], dtype=float32),\n",
       " 'pose1_rotation': array([[-0.       ,  0.       , -0.6647678,  0.74705  ]], dtype=float32)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_path = os.path.join(train_path, train[1])\n",
    "action_path = os.path.join(element_path, \"action.pkl\")\n",
    "assert os.path.exists(action_path)\n",
    "\n",
    "with open(action_path, \"rb\") as f:\n",
    "    action = pickle.load(f)\n",
    "\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: [0.4625     0.109375   0.05065918]\n",
      "Encoded: ['<extra_id_1177>', '<extra_id_1148>', '<extra_id_1144>']\n",
      "Decoded: [0.4625 0.1    0.05  ]\n"
     ]
    }
   ],
   "source": [
    "from data_processing.pose_quantizer import PoseQuantizer\n",
    "\n",
    "pq = PoseQuantizer(-0.5, 0.75, 100)\n",
    "print(\"Original: \" + str(action['pose0_position'][0]))\n",
    "enc = pq.encode_array(action['pose0_position'][0])\n",
    "print(\"Encoded: \" + str(enc))\n",
    "dec = pq.decode_array(enc)\n",
    "print(\"Decoded: \" + str(dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:45:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 17 tasks loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'end_effector_type': 'suction',\n",
       " 'n_objects': 3,\n",
       " 'difficulty': 'easy',\n",
       " 'views': ['front', 'top'],\n",
       " 'modalities': ['rgb', 'segm'],\n",
       " 'seed': 113574,\n",
       " 'action_bounds': {'low': array([ 0.25, -0.5 ,  0.  ], dtype=float32),\n",
       "  'high': array([0.75, 0.5 , 0.32], dtype=float32)},\n",
       " 'robot_components': [2, 3, 4],\n",
       " 'obj_id_to_info': {5: {'obj_name': 'square',\n",
       "   'obj_assets': 'square/square-template-allsides.urdf',\n",
       "   'obj_size_range': SizeRange(low=(0.2, 0.04, 0.001), high=(0.2, 0.04, 0.001)),\n",
       "   'obj_from_template': True,\n",
       "   'obj_replace_fn': <function vimasim.tasks.components.encyclopedia.replace_fns.container_replace_fn(*args, **kwargs)>,\n",
       "   'obj_pose_transform_fn': None,\n",
       "   'obj_alias': None,\n",
       "   'obj_novel_name': None,\n",
       "   'obj_template_file': None,\n",
       "   'obj_symmetry': None,\n",
       "   'obj_profile': <ProfilePedia.SQUARE_LIKE: 0>,\n",
       "   'texture_name': 'wooden',\n",
       "   'texture_color_value': None,\n",
       "   'texture_texture_asset': '/home/user/workspace/yunfan/code/VimaSim/vimasim/tasks/assets/textures/wood_light.png',\n",
       "   'texture_alias': None,\n",
       "   'texture_novel_name': None},\n",
       "  6: {'obj_name': 'letter V',\n",
       "   'obj_assets': 'kitting/object-template.urdf',\n",
       "   'obj_size_range': SizeRange(low=(0.14400000000000002, 0.14400000000000002, 0.036000000000000004), high=(0.14400000000000002, 0.14400000000000002, 0.036000000000000004)),\n",
       "   'obj_from_template': True,\n",
       "   'obj_replace_fn': functools.partial(<function _kit_obj_common at 0x7fcf64d124c0>, fname='capital_letter_v.obj'),\n",
       "   'obj_pose_transform_fn': None,\n",
       "   'obj_alias': None,\n",
       "   'obj_novel_name': None,\n",
       "   'obj_template_file': None,\n",
       "   'obj_symmetry': 6.283185307179586,\n",
       "   'obj_profile': <ProfilePedia.UNDETERMINED: -1>,\n",
       "   'texture_name': 'green swirl',\n",
       "   'texture_color_value': None,\n",
       "   'texture_texture_asset': '/home/user/workspace/yunfan/code/VimaSim/vimasim/tasks/assets/textures/swirls/green_swirl.jpg',\n",
       "   'texture_alias': None,\n",
       "   'texture_novel_name': None},\n",
       "  7: {'obj_name': 'letter T',\n",
       "   'obj_assets': 'kitting/object-template.urdf',\n",
       "   'obj_size_range': SizeRange(low=(0.14400000000000002, 0.14400000000000002, 0.036000000000000004), high=(0.14400000000000002, 0.14400000000000002, 0.036000000000000004)),\n",
       "   'obj_from_template': True,\n",
       "   'obj_replace_fn': functools.partial(<function _kit_obj_common at 0x7fcf64d124c0>, fname='capital_letter_t.obj'),\n",
       "   'obj_pose_transform_fn': None,\n",
       "   'obj_alias': None,\n",
       "   'obj_novel_name': None,\n",
       "   'obj_template_file': None,\n",
       "   'obj_symmetry': 6.283185307179586,\n",
       "   'obj_profile': <ProfilePedia.UNDETERMINED: -1>,\n",
       "   'texture_name': 'blue',\n",
       "   'texture_color_value': (0.3058823529411765,\n",
       "    0.4745098039215686,\n",
       "    0.6549019607843137),\n",
       "   'texture_texture_asset': None,\n",
       "   'texture_alias': None,\n",
       "   'texture_novel_name': None}},\n",
       " 'prompt': 'Put the {dragged_obj_1} into the {base_obj}.',\n",
       " 'prompt_assets': {'base_obj': {'rgb': {'front': array([[[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]],\n",
       "    \n",
       "           [[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]],\n",
       "    \n",
       "           [[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]]], dtype=uint8),\n",
       "    'top': array([[[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]],\n",
       "    \n",
       "           [[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]],\n",
       "    \n",
       "           [[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]]], dtype=uint8)},\n",
       "   'segm': {'front': array([[255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           ...,\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255]], dtype=uint8),\n",
       "    'top': array([[255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           ...,\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255]], dtype=uint8),\n",
       "    'obj_info': {'obj_id': 0, 'obj_name': 'square', 'obj_color': 'wooden'}},\n",
       "   'placeholder_type': 'object'},\n",
       "  'dragged_obj_1': {'rgb': {'front': array([[[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]],\n",
       "    \n",
       "           [[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]],\n",
       "    \n",
       "           [[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]]], dtype=uint8),\n",
       "    'top': array([[[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]],\n",
       "    \n",
       "           [[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]],\n",
       "    \n",
       "           [[255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            ...,\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255],\n",
       "            [255, 255, 255, ..., 255, 255, 255]]], dtype=uint8)},\n",
       "   'segm': {'front': array([[255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           ...,\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255]], dtype=uint8),\n",
       "    'top': array([[255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           ...,\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255],\n",
       "           [255, 255, 255, ..., 255, 255, 255]], dtype=uint8),\n",
       "    'obj_info': {'obj_id': 0,\n",
       "     'obj_name': 'letter V',\n",
       "     'obj_color': 'green swirl'}},\n",
       "   'placeholder_type': 'object'}},\n",
       " 'steps': 1,\n",
       " 'success': True,\n",
       " 'failure': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_path = os.path.join(train_path, train[1])\n",
    "trajectory_path = os.path.join(element_path, \"trajectory.pkl\")\n",
    "assert os.path.exists(trajectory_path)\n",
    "\n",
    "with open(trajectory_path, \"rb\") as f:\n",
    "    trajectory = pickle.load(f)\n",
    "\n",
    "\n",
    "trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train:\n",
    "    element_path = os.path.join(train_path, data)\n",
    "    trajectory_path = os.path.join(element_path, \"trajectory.pkl\")\n",
    "    assert os.path.exists(trajectory_path)\n",
    "\n",
    "    with open(trajectory_path, \"rb\") as f:\n",
    "        trajectory = pickle.load(f)\n",
    "    print(trajectory['action_bounds'])\n",
    "\n",
    "#trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 11:50:34.138457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-08 11:50:35.257844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/greg/miniconda3/envs/nlp_class/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-12-08 11:50:35.257910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/greg/miniconda3/envs/nlp_class/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-12-08 11:50:35.257917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 1041, 10, 7663, 10, 32022, 32028, 32056, 11981, 10, 32059, 32059, 32059, 32000, 1041, 10, 7663, 10, 32022, 32049, 32057, 11981, 10, 32059, 32059, 32000, 32085, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "        \"t5-base\", model_max_length=256, extra_ids=1200) \n",
    "\n",
    "res = tokenizer(\"<pad>action: pose: <extra_id_1177><extra_id_1171><extra_id_1143> rotation: <extra_id_1140><extra_id_1140><extra_id_1140><extra_id_1199> action: pose: <extra_id_1177><extra_id_1150><extra_id_1142> rotation: <extra_id_1140><extra_id_1140><extra_id_1199><extra_id_1114>\", max_length=28, truncation=True, padding='max_length')\n",
    "tokens = res['input_ids']\n",
    "#tokens.insert(0,0)\n",
    "\n",
    "#print(tokenizer.bos_token)\n",
    "#tokenizer.convert_ids_to_tokens(0)\n",
    "#tokenizer.decode(tokens)\n",
    "res\n",
    "#res = np.array(res)\n",
    "#print(res)\n",
    "#masks = np.ones((res.shape[-1], res.shape[-1]))\n",
    "#masks = np.triu(masks, 1)\n",
    "#masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE SHAPE: (128, 256, 3)\n",
      "IMAGE TENSOR SHAPE: (384, 384, 3)\n",
      "[[[ 1.9577874  2.1309524  2.3437037]\n",
      "  [ 1.9663497  2.1397057  2.3524182]\n",
      "  [ 2.0091617  2.1834733  2.3959913]\n",
      "  ...\n",
      "  [ 2.040557   2.2155695  2.4279447]\n",
      "  [ 1.9834745  2.1572127  2.3698473]\n",
      "  [ 1.9064132  2.0784314  2.2914162]]\n",
      "\n",
      " [[ 1.9663497  2.1397057  2.3524182]\n",
      "  [ 1.9535064  2.1265757  2.3393464]\n",
      "  [ 1.923538   2.0959384  2.3088453]\n",
      "  ...\n",
      "  [ 1.5838969  1.7487161  1.9631662]\n",
      "  [ 1.9363816  2.1090686  2.3219173]\n",
      "  [ 2.0690982  2.2447479  2.4569933]]\n",
      "\n",
      " [[ 2.0063074  2.1805553  2.3930862]\n",
      "  [ 1.9849015  2.1586719  2.3712997]\n",
      "  [ 1.903559   2.0755134  2.288511 ]\n",
      "  ...\n",
      "  [ 1.1767083  1.3324386  1.5487388]\n",
      "  [ 1.9135486  2.085726   2.2986784]\n",
      "  [ 2.2060962  2.384804   2.5964267]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  ...\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]]\n",
      "\n",
      " [[-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  ...\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]]\n",
      "\n",
      " [[-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  ...\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:45:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 17 tasks loaded\n"
     ]
    }
   ],
   "source": [
    "import data_processing.process_data\n",
    "\n",
    "path = \"/media/NLP/simple_manipulation/train/\"\n",
    "element_path = os.path.join(path, '000000')\n",
    "data_processing.process_data.processDataPoint(element_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 15:08:37.903823: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 15:08:37.903860: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-06 15:08:37.903864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "    # attributes\n",
       "    config = UnifiedIOConfig(vocab_size=33152, image_vocab_size=16384, image_patch_size=16, dtype='float32', emb_dim=512, num_heads=6, num_encoder_layers=8, num_decoder_layers=8, head_dim=64, mlp_dim=1024, mlp_activations=('gelu', 'linear'), dropout_rate=0.0, logits_via_embedding=True, float32_attention_logits=False, encoder_max_image_length=576, encoder_max_text_length=256, decoder_max_image_length=256, decoder_max_text_length=256, visual_backbone_type=None, visual_backbone_feature=None, default_image_size=(384, 384), num_seg_emb=2)\n",
       "    vae_config = VAEConfig(embed_dim=256, n_embed=16384, double_z=False, z_channels=256, resolution=256, in_channels=3, out_ch=3, ch=128, ch_mult=(1, 1, 2, 2, 4), num_res_blocks=2, attn_resolutions=(16,), dropout=0, dtype='float32')\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax.training import train_state, checkpoints\n",
    "from flax.training.common_utils import shard\n",
    "from uio import utils\n",
    "from uio import network\n",
    "from uio.configs import CONFIGS, VAE_CONFIG\n",
    "from uio.model import UnifiedIOModel\n",
    "\n",
    "def init_train_state(\n",
    "    model, params, learning_rate\n",
    ") -> train_state.TrainState:\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn = model.module.apply,\n",
    "        tx=optimizer,\n",
    "        params=params\n",
    "    )\n",
    "\n",
    "conf = CONFIGS[\"small\"]\n",
    "module = network.Transformer(config=conf, vae_config=VAE_CONFIG)\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnifiedIOModel()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UnifiedIOModel(module, text_decoder_length=28, image_decoder_length=1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = utils.load_checkpoint(\"/home/greg/NLP-Final/unified-io-inference/base.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35285/1899788700.py:1: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  sum(p.size for p in jax.tree_leaves(params))/10e6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31.7520771"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.size for p in jax.tree_leaves(params))/10e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 15:10:00.092182: W external/org_tensorflow/tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:497] The NVIDIA driver's CUDA version is 11.7 which is older than the ptxas CUDA version (11.8.89). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "state = init_train_state(model, params, learning_rate=5e-5)#decrease by 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"VIMA/VIMA-Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlp_class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "78a98554bd959fe647588642884065a24bb8267d1904c1c950aa6b68cc3632ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
