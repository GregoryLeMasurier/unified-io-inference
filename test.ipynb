{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "path = \"/media/NLP/simple_manipulation\"\n",
    "train_path = os.path.join(path, \"train\")\n",
    "val_path = os.path.join(path, \"val\")\n",
    "test_path = os.path.join(path, \"test\")\n",
    "\n",
    "train = os.listdir(train_path)\n",
    "train = train[0:100]\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $element_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_path = os.path.join(train_path, train[1])\n",
    "action_path = os.path.join(element_path, \"action.pkl\")\n",
    "assert os.path.exists(action_path)\n",
    "\n",
    "with open(action_path, \"rb\") as f:\n",
    "    action = pickle.load(f)\n",
    "\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose_quantizer import PoseQuantizer\n",
    "\n",
    "pq = PoseQuantizer(-0.5, 0.75, 100)\n",
    "print(\"Original: \" + str(action['pose0_position'][0]))\n",
    "enc = pq.encode_array(action['pose0_position'][0])\n",
    "print(\"Encoded: \" + str(enc))\n",
    "dec = pq.decode_array(enc)\n",
    "print(\"Decoded: \" + str(dec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_path = os.path.join(train_path, train[1])\n",
    "trajectory_path = os.path.join(element_path, \"trajectory.pkl\")\n",
    "assert os.path.exists(trajectory_path)\n",
    "\n",
    "with open(trajectory_path, \"rb\") as f:\n",
    "    trajectory = pickle.load(f)\n",
    "\n",
    "\n",
    "trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train:\n",
    "    element_path = os.path.join(train_path, data)\n",
    "    trajectory_path = os.path.join(element_path, \"trajectory.pkl\")\n",
    "    assert os.path.exists(trajectory_path)\n",
    "\n",
    "    with open(trajectory_path, \"rb\") as f:\n",
    "        trajectory = pickle.load(f)\n",
    "    print(trajectory['action_bounds'])\n",
    "\n",
    "#trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[39m=\u001b[39m T5Tokenizer\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      6\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mt5-base\u001b[39m\u001b[39m\"\u001b[39m, model_max_length\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m, extra_ids\u001b[39m=\u001b[39m\u001b[39m1200\u001b[39m) \n\u001b[0;32m----> 8\u001b[0m res,msk \u001b[39m=\u001b[39m tokenizer(\u001b[39m\"\u001b[39m\u001b[39maction pose <extra_id_1177><extra_id_1171><extra_id_1143> rotation <extra_id_1140><extra_id_1140><extra_id_1140><extra_id_1199> action pose <extra_id_1177><extra_id_1150><extra_id_1142> rotation <extra_id_1140><extra_id_1140><extra_id_1199><extra_id_1114>\u001b[39m\u001b[39m\"\u001b[39m, max_length\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[39m#tokenizer.decode(res)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(res)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "        \"t5-base\", model_max_length=256, extra_ids=1200) \n",
    "\n",
    "res = tokenizer(\"action pose <extra_id_1177><extra_id_1171><extra_id_1143> rotation <extra_id_1140><extra_id_1140><extra_id_1140><extra_id_1199> action pose <extra_id_1177><extra_id_1150><extra_id_1142> rotation <extra_id_1140><extra_id_1140><extra_id_1199><extra_id_1114>\", max_length=64, truncation=True, padding='max_length')['input_ids']\n",
    "\n",
    "#tokenizer.decode(res)\n",
    "res = np.array(res)\n",
    "print(res)\n",
    "masks = np.ones((res.shape[-1], res.shape[-1]))\n",
    "masks = np.triu(masks, 1)\n",
    "masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE SHAPE: (128, 256, 3)\n",
      "IMAGE TENSOR SHAPE: (384, 384, 3)\n",
      "[[[ 1.9577874  2.1309524  2.3437037]\n",
      "  [ 1.9663497  2.1397057  2.3524182]\n",
      "  [ 2.0091617  2.1834733  2.3959913]\n",
      "  ...\n",
      "  [ 2.040557   2.2155695  2.4279447]\n",
      "  [ 1.9834745  2.1572127  2.3698473]\n",
      "  [ 1.9064132  2.0784314  2.2914162]]\n",
      "\n",
      " [[ 1.9663497  2.1397057  2.3524182]\n",
      "  [ 1.9535064  2.1265757  2.3393464]\n",
      "  [ 1.923538   2.0959384  2.3088453]\n",
      "  ...\n",
      "  [ 1.5838969  1.7487161  1.9631662]\n",
      "  [ 1.9363816  2.1090686  2.3219173]\n",
      "  [ 2.0690982  2.2447479  2.4569933]]\n",
      "\n",
      " [[ 2.0063074  2.1805553  2.3930862]\n",
      "  [ 1.9849015  2.1586719  2.3712997]\n",
      "  [ 1.903559   2.0755134  2.288511 ]\n",
      "  ...\n",
      "  [ 1.1767083  1.3324386  1.5487388]\n",
      "  [ 1.9135486  2.085726   2.2986784]\n",
      "  [ 2.2060962  2.384804   2.5964267]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  ...\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]]\n",
      "\n",
      " [[-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  ...\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]]\n",
      "\n",
      " [[-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  ...\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]\n",
      "  [-2.117904  -2.0357144 -1.8044444]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:45:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 17 tasks loaded\n"
     ]
    }
   ],
   "source": [
    "import process_data\n",
    "\n",
    "path = \"/media/NLP/simple_manipulation/train/\"\n",
    "element_path = os.path.join(path, '000000')\n",
    "process_data.processDataPoint(element_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nlp_class')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78a98554bd959fe647588642884065a24bb8267d1904c1c950aa6b68cc3632ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
